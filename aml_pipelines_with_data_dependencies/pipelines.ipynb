{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Azure Machine Learning Pipelines with Data Dependency\n",
        "\n",
        "We will see how we can build a pipeline with implicit data dependency."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace, Experiment, Datastore\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget, ComputeInstance\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)\n",
        "\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.pipeline.core import Pipeline, PipelineData\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "print(\"Pipeline SDK-specific imports completed\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.51.0\nPipeline SDK-specific imports completed\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1712813233760
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# source directory\n",
        "source_directory = '_run_train'\n",
        "    \n",
        "print('Sample scripts will be created in {} directory.'.format(source_directory))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sample scripts will be created in _run_train directory.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813233959
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
        "\n",
        "# Default datastore (Azure blob storage)\n",
        "# def_blob_store = ws.get_default_datastore()\n",
        "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
        "print(\"Blobstore's name: {}\".format(def_blob_store.name))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813234796
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference the data uploaded to blob storage using DataReference\n",
        "# Assign the datasource to blob_input_data variable\n",
        "\n",
        "# DataReference(datastore, \n",
        "#               data_reference_name=None, \n",
        "#               path_on_datastore=None, \n",
        "#               mode='mount', \n",
        "#               path_on_compute=None, \n",
        "#               overwrite=False)\n",
        "\n",
        "blob_input_data = DataReference(\n",
        "    datastore=def_blob_store,\n",
        "    data_reference_name=\"test_data\",\n",
        "    path_on_datastore=\"titanic/Titanic.csv\")\n",
        "print(\"Step 1: DataReference object created\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Step 1: DataReference object created\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813234923
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the compute target\n",
        "aml_compute_target = \"CPU-MD\"\n",
        "\n",
        "# Try to get the existing compute instance\n",
        "aml_compute = AmlCompute(ws, aml_compute_target)\n",
        "print(\"Step 2: AML Compute target created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Step 2: AML Compute target created.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813235131
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intermediate/Output Data\n",
        "\n",
        "Intermediate data (or output of a Step) is represented by PipelineData object. PipelineData can be produced by one step and consumed in another step by providing the PipelineData object as an output of one step and the input of one or more steps."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define intermediate data using PipelineData\n",
        "# PipelineData(name, \n",
        "#              datastore=None, \n",
        "#              output_name=None, \n",
        "#              output_mode='mount', \n",
        "#              output_path_on_compute=None, \n",
        "#              output_overwrite=None, \n",
        "#              data_type=None, \n",
        "#              is_directory=None)\n",
        "\n",
        "# Naming the intermediate data as processed_data1 and assigning it to the variable processed_data1.\n",
        "processed_data1 = PipelineData(\"processed_data1\",datastore=def_blob_store, is_directory=True)\n",
        "print(\"Step 3: PipelineData object created\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Step 3: PipelineData object created\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813235253
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Pipelines steps using datasources and intermediate data\n",
        "\n",
        "Machine learning pipelines can have many steps and these steps could use or reuse datasources and intermediate data. Here's how we construct such a pipeline:\n",
        "\n",
        "##### Define a Step that consumes a datasource and produces intermediate data.\n",
        "\n",
        "In this step, we define a step that consumes a datasource and produces intermediate data.\n",
        "\n",
        "Open train.py in the local machine and examine the arguments, inputs, and outputs for the script. That will give you a good sense of why the script argument names used below are important.\n",
        "Specify conda dependencies and a base docker image through a RunConfiguration\n",
        "\n",
        "This step uses a docker image and scikit-learn, use a RunConfiguration to specify these requirements and use when creating the PythonScriptStep.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import DockerConfiguration, RunConfiguration, DEFAULT_CPU_IMAGE\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# create a new runconfig object\n",
        "run_config = RunConfiguration()\n",
        "\n",
        "# enable Docker using the DockerConfiguration object\n",
        "run_config.docker = DockerConfiguration(use_docker=True)\n",
        "\n",
        "# set Docker base image to the default CPU-based image\n",
        "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
        "\n",
        "# use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
        "run_config.environment.python.user_managed_dependencies = False\n",
        "\n",
        "# specify CondaDependencies obj\n",
        "run_config.environment.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn'])"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813235370
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Define a Step that consumes intermediate data and produces intermediate data\n",
        "\n",
        "In this step, we define a step that consumes an intermediate data and produces intermediate data.\n",
        "\n",
        "Open extract.py in the local machine and examine the arguments, inputs, and outputs for the script. That will give you a good sense of why the script argument names used below are important.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step4 consumes the datasource (Datareference) in the previous step\n",
        "# and produces processed_data1\n",
        "trainStep = PythonScriptStep(\n",
        "    script_name=\"train.py\", \n",
        "    arguments=[\"--input_data\", blob_input_data, \"--output_train\", processed_data1],\n",
        "    inputs=[blob_input_data],\n",
        "    outputs=[processed_data1],\n",
        "    compute_target=aml_compute, \n",
        "    source_directory=source_directory,\n",
        "    runconfig=run_config\n",
        ")\n",
        "print(\"Step 4: trainStep created\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Step 4: trainStep created\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813235500
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Define a Step that consumes intermediate data and produces intermediate data\n",
        "\n",
        "In this step, we define a step that consumes an intermediate data and produces intermediate data.\n",
        "\n",
        "Open extract.py in the local machine and examine the arguments, inputs, and outputs for the script. That will give you a good sense of why the script argument names used below are important.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step5 to use the intermediate data produced by step4\n",
        "# This step also produces an output processed_data2\n",
        "processed_data2 = PipelineData(\"processed_data2\", datastore=def_blob_store, is_directory=True)\n",
        "source_directory = \"_run_extract\"\n",
        "\n",
        "extractStep = PythonScriptStep(\n",
        "    script_name=\"extract.py\",\n",
        "    arguments=[\"--input_extract\", processed_data1, \"--output_extract\", processed_data2],\n",
        "    inputs=[processed_data1],\n",
        "    outputs=[processed_data2],\n",
        "    compute_target=aml_compute, \n",
        "    source_directory=source_directory)\n",
        "print(\"Step 5: extractStep created\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Step 5: extractStep created\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813235641
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Define a Step that consumes intermediate data and existing data and produces intermediate data\n",
        "\n",
        "In this step, we define a step that consumes multiple data types and produces intermediate data.\n",
        "\n",
        "This step uses the output generated from the previous step as well as existing data on a DataStore. The location of the existing data is specified using a PipelineParameter and a DataPath. Using a PipelineParameter enables easy modification of the data location when the Pipeline is published and resubmitted.\n",
        "\n",
        "Open compare.py in the local machine and examine the arguments, inputs, and outputs for the script. That will give you a good sense of why the script argument names used below are important.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference the data uploaded to blob storage using a PipelineParameter and a DataPath\n",
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
        "\n",
        "datapath = DataPath(datastore=def_blob_store, path_on_datastore='titanic/Titanic.csv')\n",
        "datapath_param = PipelineParameter(name=\"compare_data\", default_value=datapath)\n",
        "data_parameter1 = (datapath_param, DataPathComputeBinding(mode='mount'))"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813235758
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now define the compare step which takes two inputs and produces an output\n",
        "processed_data3 = PipelineData(\"processed_data3\", datastore=def_blob_store, is_directory=True)\n",
        "source_directory = \"_run_compare\"\n",
        "\n",
        "compareStep = PythonScriptStep(\n",
        "    script_name=\"compare.py\",\n",
        "    arguments=[\"--compare_data1\", data_parameter1, \"--compare_data2\", processed_data2, \"--output_compare\", processed_data3],\n",
        "    inputs=[data_parameter1, processed_data2],\n",
        "    outputs=[processed_data3],    \n",
        "    compute_target=aml_compute, \n",
        "    source_directory=source_directory)\n",
        "print(\"Step 6: compareStep created\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Step 6: compareStep created\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813235899
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build Pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline1 = Pipeline(workspace=ws, steps=[compareStep])\n",
        "print (\"Pipeline is built\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline is built\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813241121
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run1 = Experiment(ws, 'Data_dependency_sample').submit(pipeline1)\n",
        "print(\"Pipeline is submitted for execution\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813249799
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(pipeline_run1).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c485500974fd4e9aad49a273a18fa9b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/4a0c386a-ebf2-40ac-91bd-55b47a668007?wsid=/subscriptions/f242a3b6-370c-4b2e-971d-a0399c53d6f0/resourcegroups/TAFE-TST-ARG-DS/workspaces/ZEMLSWSBI01T&tid=66269612-ce5a-482e-8ea4-fdf6b5ad33af\", \"run_id\": \"4a0c386a-ebf2-40ac-91bd-55b47a668007\", \"run_properties\": {\"run_id\": \"4a0c386a-ebf2-40ac-91bd-55b47a668007\", \"created_utc\": \"2024-04-11T05:27:29.19865Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.continue_on_failed_optional_input\": \"True\", \"azureml.pipelineComponent\": \"pipelinerun\", \"azureml.pipelines.stages\": \"{\\\"Initialization\\\":null,\\\"Execution\\\":{\\\"StartTime\\\":\\\"2024-04-11T05:27:30.2615456+00:00\\\",\\\"EndTime\\\":\\\"2024-04-11T05:27:57.7050027+00:00\\\",\\\"Status\\\":\\\"Finished\\\"}}\"}, \"tags\": {}, \"end_time_utc\": \"2024-04-11T05:27:57.804414Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://zemlsstorbi01t.blob.core.windows.net/azureml/ExperimentRun/dcid.4a0c386a-ebf2-40ac-91bd-55b47a668007/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=5ICCPnYjr2MknaZhw4DkZj2G6TNaHtmcUU%2Bb1M0ZYZM%3D&skoid=e977d5ee-0c02-4489-924b-b957d28af788&sktid=66269612-ce5a-482e-8ea4-fdf6b5ad33af&skt=2024-04-11T00%3A06%3A44Z&ske=2024-04-12T08%3A16%3A44Z&sks=b&skv=2019-07-07&st=2024-04-11T05%3A29%3A03Z&se=2024-04-11T13%3A39%3A03Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://zemlsstorbi01t.blob.core.windows.net/azureml/ExperimentRun/dcid.4a0c386a-ebf2-40ac-91bd-55b47a668007/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=Fc6HUugYqtmuam6xYKo%2FP6MIiKcKJ47kp5ZlYn7dKgY%3D&skoid=e977d5ee-0c02-4489-924b-b957d28af788&sktid=66269612-ce5a-482e-8ea4-fdf6b5ad33af&skt=2024-04-11T00%3A06%3A44Z&ske=2024-04-12T08%3A16%3A44Z&sks=b&skv=2019-07-07&st=2024-04-11T05%3A29%3A03Z&se=2024-04-11T13%3A39%3A03Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://zemlsstorbi01t.blob.core.windows.net/azureml/ExperimentRun/dcid.4a0c386a-ebf2-40ac-91bd-55b47a668007/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=BOiYui6qUzB1WYRDgud4rdaODMwnmxQOyYU8zMaBNMs%3D&skoid=e977d5ee-0c02-4489-924b-b957d28af788&sktid=66269612-ce5a-482e-8ea4-fdf6b5ad33af&skt=2024-04-11T00%3A06%3A44Z&ske=2024-04-12T08%3A16%3A44Z&sks=b&skv=2019-07-07&st=2024-04-11T05%3A29%3A03Z&se=2024-04-11T13%3A39%3A03Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:00:28\", \"run_number\": \"1712813249\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"89f1f95a-de2e-4c55-b260-d72ae0f0b8e5\", \"name\": \"compare.py\", \"status\": \"Finished\", \"start_time\": \"2024-04-11T05:27:42.886219Z\", \"created_time\": \"2024-04-11T05:27:34.505191Z\", \"end_time\": \"2024-04-11T05:27:56.561012Z\", \"duration\": \"0:00:22\", \"run_number\": 1712813254, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2024-04-11T05:27:34.505191Z\", \"is_reused\": \"\"}, {\"run_id\": \"a23098b7-af75-4f43-a4cc-ecf70aa4c24e\", \"name\": \"extract.py\", \"status\": \"Finished\", \"start_time\": \"2024-04-11T05:27:32.022631Z\", \"created_time\": \"2024-04-11T05:27:31.890415Z\", \"end_time\": \"2024-04-11T05:27:32.022631Z\", \"duration\": \"0:00:00\", \"run_number\": 1712813251, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2024-04-11T05:27:31.890415Z\", \"is_reused\": \"Yes\"}, {\"run_id\": \"7a5cf0cf-3b8f-4bba-b8b2-e1c19ab70aca\", \"name\": \"train.py\", \"status\": \"Finished\", \"start_time\": \"2024-04-11T05:27:30.706681Z\", \"created_time\": \"2024-04-11T05:27:30.57313Z\", \"end_time\": \"2024-04-11T05:27:30.706681Z\", \"duration\": \"0:00:00\", \"run_number\": 1712813250, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2024-04-11T05:27:30.57313Z\", \"is_reused\": \"Yes\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2024-04-11 05:27:30Z] Completing processing run id 7a5cf0cf-3b8f-4bba-b8b2-e1c19ab70aca.\\n[2024-04-11 05:27:31Z] Completing processing run id a23098b7-af75-4f43-a4cc-ecf70aa4c24e.\\n[2024-04-11 05:27:33Z] Submitting 1 runs, first five are: fb14f913:89f1f95a-de2e-4c55-b260-d72ae0f0b8e5\\n[2024-04-11 05:27:57Z] Completing processing run id 89f1f95a-de2e-4c55-b260-d72ae0f0b8e5.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"73eda45a\": {\"node_id\": \"73eda45a\", \"name\": \"Data source for data path parameter compare_data\"}, \"b2f4b04f\": {\"node_id\": \"b2f4b04f\", \"name\": \"test_data\"}}, \"module_nodes\": {\"fb14f913\": {\"node_id\": \"fb14f913\", \"name\": \"compare.py\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"89f1f95a-de2e-4c55-b260-d72ae0f0b8e5\"}, \"cb5e39c0\": {\"node_id\": \"cb5e39c0\", \"name\": \"extract.py\", \"status\": \"Finished\", \"_is_reused\": true, \"run_id\": \"a23098b7-af75-4f43-a4cc-ecf70aa4c24e\"}, \"f05fb4c3\": {\"node_id\": \"f05fb4c3\", \"name\": \"train.py\", \"status\": \"Finished\", \"_is_reused\": true, \"run_id\": \"7a5cf0cf-3b8f-4bba-b8b2-e1c19ab70aca\"}}, \"edges\": [{\"source_node_id\": \"73eda45a\", \"source_node_name\": \"Data source for data path parameter compare_data\", \"source_name\": \"data\", \"target_name\": \"workspaceblobstore_1314715e\", \"dst_node_id\": \"fb14f913\", \"dst_node_name\": \"compare.py\"}, {\"source_node_id\": \"cb5e39c0\", \"source_node_name\": \"extract.py\", \"source_name\": \"processed_data2\", \"target_name\": \"workspaceblobstore_1314715e\", \"dst_node_id\": \"fb14f913\", \"dst_node_name\": \"compare.py\"}, {\"source_node_id\": \"f05fb4c3\", \"source_node_name\": \"train.py\", \"source_name\": \"processed_data1\", \"target_name\": \"processed_data1\", \"dst_node_id\": \"cb5e39c0\", \"dst_node_name\": \"extract.py\"}, {\"source_node_id\": \"b2f4b04f\", \"source_node_name\": \"test_data\", \"source_name\": \"data\", \"target_name\": \"test_data\", \"dst_node_id\": \"f05fb4c3\", \"dst_node_name\": \"train.py\"}], \"child_runs\": [{\"run_id\": \"89f1f95a-de2e-4c55-b260-d72ae0f0b8e5\", \"name\": \"compare.py\", \"status\": \"Finished\", \"start_time\": \"2024-04-11T05:27:42.886219Z\", \"created_time\": \"2024-04-11T05:27:34.505191Z\", \"end_time\": \"2024-04-11T05:27:56.561012Z\", \"duration\": \"0:00:22\", \"run_number\": 1712813254, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2024-04-11T05:27:34.505191Z\", \"is_reused\": \"\"}, {\"run_id\": \"a23098b7-af75-4f43-a4cc-ecf70aa4c24e\", \"name\": \"extract.py\", \"status\": \"Finished\", \"start_time\": \"2024-04-11T05:27:32.022631Z\", \"created_time\": \"2024-04-11T05:27:31.890415Z\", \"end_time\": \"2024-04-11T05:27:32.022631Z\", \"duration\": \"0:00:00\", \"run_number\": 1712813251, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2024-04-11T05:27:31.890415Z\", \"is_reused\": \"Yes\"}, {\"run_id\": \"7a5cf0cf-3b8f-4bba-b8b2-e1c19ab70aca\", \"name\": \"train.py\", \"status\": \"Finished\", \"start_time\": \"2024-04-11T05:27:30.706681Z\", \"created_time\": \"2024-04-11T05:27:30.57313Z\", \"end_time\": \"2024-04-11T05:27:30.706681Z\", \"duration\": \"0:00:00\", \"run_number\": 1712813250, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2024-04-11T05:27:30.57313Z\", \"is_reused\": \"Yes\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.51.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813327881
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run1.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813332344
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Steps\n",
        "for step in pipeline_run1.get_steps():\n",
        "    print(\"Outputs of step \" + step.name)\n",
        "    \n",
        "    # Get a dictionary of StepRunOutputs with the output name as the key \n",
        "    output_dict = step.get_outputs()\n",
        "    \n",
        "    for name, output in output_dict.items():\n",
        "        \n",
        "        output_reference = output.get_port_data_reference() # Get output port data reference\n",
        "        print(\"\\tname: \" + name)\n",
        "        print(\"\\tdatastore: \" + output_reference.datastore_name)\n",
        "        print(\"\\tpath on datastore: \" + output_reference.path_on_datastore)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813357010
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the step runs by name 'train.py'\n",
        "train_step = pipeline_run1.find_step_run('train.py')\n",
        "\n",
        "if train_step:\n",
        "    train_step_obj = train_step[0] # since we have only one step by name 'train.py'\n",
        "    train_step_obj.get_output_data('processed_data1').download(\"./outputs\") # download the output to current directory"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712813385197
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "version_major": 2,
        "version_minor": 0,
        "state": {
          "undefined": {
            "model_name": "ShowPipelineRunsModel",
            "model_module": "azureml_widgets",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "WidgetModel",
              "_model_module": "@jupyter-widgets/base",
              "msg": "Model class 'ShowPipelineRunsModel' from module 'azureml_widgets' is loaded but can not be instantiated",
              "tooltip": null,
              "_view_name": "ErrorWidgetView",
              "tabbable": null,
              "_view_module": "@jupyter-widgets/base",
              "error": {},
              "_dom_classes": [],
              "_view_count": null,
              "_model_module_version": "2.0.0"
            }
          },
          "b8cfa010dd744c73bba48b4cbfe71666": {
            "model_name": "LayoutModel",
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "1.2.0",
            "state": {
              "_view_module_version": "1.2.0",
              "_model_name": "LayoutModel",
              "grid_row": null,
              "_model_module": "@jupyter-widgets/base",
              "overflow": null,
              "max_height": null,
              "display": null,
              "border_top": null,
              "grid_auto_flow": null,
              "grid_template_rows": null,
              "align_self": null,
              "grid_auto_columns": null,
              "width": null,
              "grid_area": null,
              "align_items": null,
              "_view_name": "LayoutView",
              "left": null,
              "height": null,
              "_view_module": "@jupyter-widgets/base",
              "border_right": null,
              "object_position": null,
              "justify_content": null,
              "bottom": null,
              "max_width": null,
              "border": null,
              "margin": null,
              "order": null,
              "grid_column": null,
              "grid_auto_rows": null,
              "padding": null,
              "grid_template_columns": null,
              "justify_items": null,
              "object_fit": null,
              "visibility": null,
              "_view_count": null,
              "flex_flow": null,
              "min_height": null,
              "top": null,
              "min_width": null,
              "flex": null,
              "border_left": null,
              "_model_module_version": "1.2.0",
              "grid_template_areas": null,
              "overflow_x": null,
              "right": null,
              "overflow_y": null,
              "grid_gap": null,
              "border_bottom": null,
              "align_content": null
            }
          },
          "e6760e358e8241d78f75da7fbbf9f9de": {
            "model_name": "LayoutModel",
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "1.2.0",
            "state": {
              "_view_module_version": "1.2.0",
              "_model_name": "LayoutModel",
              "grid_row": null,
              "_model_module": "@jupyter-widgets/base",
              "overflow": null,
              "max_height": null,
              "display": null,
              "border_top": null,
              "grid_auto_flow": null,
              "grid_template_rows": null,
              "align_self": null,
              "grid_auto_columns": null,
              "width": null,
              "grid_area": null,
              "align_items": null,
              "_view_name": "LayoutView",
              "left": null,
              "height": null,
              "_view_module": "@jupyter-widgets/base",
              "border_right": null,
              "object_position": null,
              "justify_content": null,
              "bottom": null,
              "max_width": null,
              "border": null,
              "margin": null,
              "order": null,
              "grid_column": null,
              "grid_auto_rows": null,
              "padding": null,
              "grid_template_columns": null,
              "justify_items": null,
              "object_fit": null,
              "visibility": null,
              "_view_count": null,
              "flex_flow": null,
              "min_height": null,
              "top": null,
              "min_width": null,
              "flex": null,
              "border_left": null,
              "_model_module_version": "1.2.0",
              "grid_template_areas": null,
              "overflow_x": null,
              "right": null,
              "overflow_y": null,
              "grid_gap": null,
              "border_bottom": null,
              "align_content": null
            }
          },
          "8c8cdc3ef3ef4a08adf1cac78cf2b71e": {
            "model_name": "LayoutModel",
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "1.2.0",
            "state": {
              "_view_module_version": "1.2.0",
              "_model_name": "LayoutModel",
              "grid_row": null,
              "_model_module": "@jupyter-widgets/base",
              "overflow": null,
              "max_height": null,
              "display": null,
              "border_top": null,
              "grid_auto_flow": null,
              "grid_template_rows": null,
              "align_self": null,
              "grid_auto_columns": null,
              "width": null,
              "grid_area": null,
              "align_items": null,
              "_view_name": "LayoutView",
              "left": null,
              "height": null,
              "_view_module": "@jupyter-widgets/base",
              "border_right": null,
              "object_position": null,
              "justify_content": null,
              "bottom": null,
              "max_width": null,
              "border": null,
              "margin": null,
              "order": null,
              "grid_column": null,
              "grid_auto_rows": null,
              "padding": null,
              "grid_template_columns": null,
              "justify_items": null,
              "object_fit": null,
              "visibility": null,
              "_view_count": null,
              "flex_flow": null,
              "min_height": null,
              "top": null,
              "min_width": null,
              "flex": null,
              "border_left": null,
              "_model_module_version": "1.2.0",
              "grid_template_areas": null,
              "overflow_x": null,
              "right": null,
              "overflow_y": null,
              "grid_gap": null,
              "border_bottom": null,
              "align_content": null
            }
          },
          "9c88d325921d4b86acf8e6619cb92a90": {
            "model_name": "LayoutModel",
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "1.2.0",
            "state": {
              "_view_module_version": "1.2.0",
              "_model_name": "LayoutModel",
              "grid_row": null,
              "_model_module": "@jupyter-widgets/base",
              "overflow": null,
              "max_height": null,
              "display": null,
              "border_top": null,
              "grid_auto_flow": null,
              "grid_template_rows": null,
              "align_self": null,
              "grid_auto_columns": null,
              "width": null,
              "grid_area": null,
              "align_items": null,
              "_view_name": "LayoutView",
              "left": null,
              "height": null,
              "_view_module": "@jupyter-widgets/base",
              "border_right": null,
              "object_position": null,
              "justify_content": null,
              "bottom": null,
              "max_width": null,
              "border": null,
              "margin": null,
              "order": null,
              "grid_column": null,
              "grid_auto_rows": null,
              "padding": null,
              "grid_template_columns": null,
              "justify_items": null,
              "object_fit": null,
              "visibility": null,
              "_view_count": null,
              "flex_flow": null,
              "min_height": null,
              "top": null,
              "min_width": null,
              "flex": null,
              "border_left": null,
              "_model_module_version": "1.2.0",
              "grid_template_areas": null,
              "overflow_x": null,
              "right": null,
              "overflow_y": null,
              "grid_gap": null,
              "border_bottom": null,
              "align_content": null
            }
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}